{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25e07801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas<3.0,>=2.0 in /Users/manishkumarsingh/Downloads/IISC-Root/DA 225o Deep Learning/Project/dost-com/.venv/lib/python3.13/site-packages (from -r ../requirements.txt (line 1)) (2.2.3)\n",
      "Collecting scikit-learn<1.6,>=1.4 (from -r ../requirements.txt (line 2))\n",
      "  Using cached scikit_learn-1.5.2-cp313-cp313-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Collecting torch>=2.2.0 (from -r ../requirements.txt (line 3))\n",
      "  Using cached torch-2.7.0-cp313-none-macosx_11_0_arm64.whl.metadata (29 kB)\n",
      "Collecting transformers>=4.40.0 (from -r ../requirements.txt (line 4))\n",
      "  Using cached transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting datasets>=2.19.0 (from -r ../requirements.txt (line 5))\n",
      "  Using cached datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting tqdm>=4.66.0 (from -r ../requirements.txt (line 6))\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting accelerate>=0.29.0 (from -r ../requirements.txt (line 7))\n",
      "  Using cached accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting peft>=0.10.0 (from -r ../requirements.txt (line 8))\n",
      "  Using cached peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting mlflow>=2.10.0 (from -r ../requirements.txt (line 9))\n",
      "  Using cached mlflow-2.22.0-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/manishkumarsingh/Downloads/IISC-Root/DA 225o Deep Learning/Project/dost-com/.venv/lib/python3.13/site-packages (from pandas<3.0,>=2.0->-r ../requirements.txt (line 1)) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/manishkumarsingh/Downloads/IISC-Root/DA 225o Deep Learning/Project/dost-com/.venv/lib/python3.13/site-packages (from pandas<3.0,>=2.0->-r ../requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/manishkumarsingh/Downloads/IISC-Root/DA 225o Deep Learning/Project/dost-com/.venv/lib/python3.13/site-packages (from pandas<3.0,>=2.0->-r ../requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/manishkumarsingh/Downloads/IISC-Root/DA 225o Deep Learning/Project/dost-com/.venv/lib/python3.13/site-packages (from pandas<3.0,>=2.0->-r ../requirements.txt (line 1)) (2025.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn<1.6,>=1.4->-r ../requirements.txt (line 2))\n",
      "  Using cached scipy-1.15.3-cp313-cp313-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn<1.6,>=1.4->-r ../requirements.txt (line 2))\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn<1.6,>=1.4->-r ../requirements.txt (line 2))\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting filelock (from torch>=2.2.0->-r ../requirements.txt (line 3))\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch>=2.2.0->-r ../requirements.txt (line 3))\n",
      "  Using cached typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting setuptools (from torch>=2.2.0->-r ../requirements.txt (line 3))\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.2.0->-r ../requirements.txt (line 3))\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=2.2.0->-r ../requirements.txt (line 3))\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=2.2.0->-r ../requirements.txt (line 3))\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch>=2.2.0->-r ../requirements.txt (line 3))\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers>=4.40.0->-r ../requirements.txt (line 4))\n",
      "  Using cached huggingface_hub-0.32.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/manishkumarsingh/Downloads/IISC-Root/DA 225o Deep Learning/Project/dost-com/.venv/lib/python3.13/site-packages (from transformers>=4.40.0->-r ../requirements.txt (line 4)) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers>=4.40.0->-r ../requirements.txt (line 4))\n",
      "  Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.40.0->-r ../requirements.txt (line 4))\n",
      "  Using cached regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers>=4.40.0->-r ../requirements.txt (line 4))\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.40.0->-r ../requirements.txt (line 4))\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers>=4.40.0->-r ../requirements.txt (line 4))\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub<1.0,>=0.30.0->transformers>=4.40.0->-r ../requirements.txt (line 4))\n",
      "  Using cached hf_xet-1.1.3-cp37-abi3-macosx_11_0_arm64.whl.metadata (879 bytes)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=2.19.0->-r ../requirements.txt (line 5))\n",
      "  Using cached pyarrow-20.0.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.19.0->-r ../requirements.txt (line 5))\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets>=2.19.0->-r ../requirements.txt (line 5))\n",
      "  Using cached xxhash-3.5.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=2.19.0->-r ../requirements.txt (line 5))\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec (from torch>=2.2.0->-r ../requirements.txt (line 3))\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->-r ../requirements.txt (line 5))\n",
      "  Using cached aiohttp-3.12.8-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: psutil in /Users/manishkumarsingh/Downloads/IISC-Root/DA 225o Deep Learning/Project/dost-com/.venv/lib/python3.13/site-packages (from accelerate>=0.29.0->-r ../requirements.txt (line 7)) (7.0.0)\n",
      "Collecting mlflow-skinny==2.22.0 (from mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached mlflow_skinny-2.22.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting Flask<4 (from mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached flask-3.1.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting gunicorn<24 (from mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting markdown<4,>=3.3 (from mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting matplotlib<4 (from mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached matplotlib-3.10.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=2.19.0->-r ../requirements.txt (line 5))\n",
      "  Using cached pyarrow-19.0.1-cp313-cp313-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting sqlalchemy<3,>=1.4.0 (from mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached sqlalchemy-2.0.41-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting cachetools<6,>=5.0.0 (from mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting click<9,>=7.0 (from mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting cloudpickle<4 (from mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached databricks_sdk-0.55.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting fastapi<1 (from mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting importlib_metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached opentelemetry_api-1.34.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached opentelemetry_sdk-1.34.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting packaging>=20.0 (from transformers>=4.40.0->-r ../requirements.txt (line 4))\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting protobuf<7,>=3.12.0 (from mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached protobuf-6.31.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting pydantic<3,>=1.10.8 (from mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting uvicorn<1 (from mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached uvicorn-0.34.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached google_auth-2.40.2-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting urllib3>=1.26.0 (from docker<8,>=4.0.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi<1->mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting blinker>=1.9.0 (from Flask<4->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting itsdangerous>=2.2.0 (from Flask<4->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting markupsafe>=2.1.1 (from Flask<4->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting werkzeug>=3.1.0 (from Flask<4->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting zipp>=3.20 (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached zipp-3.22.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib<4->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached contourpy-1.3.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib<4->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib<4->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached fonttools-4.58.1-cp313-cp313-macosx_10_13_universal2.whl.metadata (106 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib<4->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached kiwisolver-1.4.8-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.2 kB)\n",
      "Collecting pillow>=8 (from matplotlib<4->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached pillow-11.2.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib<4->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.55b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached opentelemetry_semantic_conventions-0.55b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached pydantic_core-2.33.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/manishkumarsingh/Downloads/IISC-Root/DA 225o Deep Learning/Project/dost-com/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=2.0->-r ../requirements.txt (line 1)) (1.17.0)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers>=4.40.0->-r ../requirements.txt (line 4))\n",
      "  Using cached charset_normalizer-3.4.2-cp313-cp313-macosx_10_13_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers>=4.40.0->-r ../requirements.txt (line 4))\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers>=4.40.0->-r ../requirements.txt (line 4))\n",
      "  Using cached certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting anyio<5,>=3.6.2 (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting sniffio>=1.1 (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11>=0.8 (from uvicorn<1->mlflow-skinny==2.22.0->mlflow>=2.10.0->-r ../requirements.txt (line 9))\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->-r ../requirements.txt (line 5))\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->-r ../requirements.txt (line 5))\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->-r ../requirements.txt (line 5))\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->-r ../requirements.txt (line 5))\n",
      "  Using cached frozenlist-1.6.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (17 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->-r ../requirements.txt (line 5))\n",
      "  Using cached multidict-6.4.4-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->-r ../requirements.txt (line 5))\n",
      "  Using cached propcache-0.3.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->-r ../requirements.txt (line 5))\n",
      "  Using cached yarl-1.20.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (72 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.2.0->-r ../requirements.txt (line 3))\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Using cached scikit_learn-1.5.2-cp313-cp313-macosx_12_0_arm64.whl (11.0 MB)\n",
      "Using cached torch-2.7.0-cp313-none-macosx_11_0_arm64.whl (68.6 MB)\n",
      "Using cached transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "Using cached huggingface_hub-0.32.4-py3-none-any.whl (512 kB)\n",
      "Using cached hf_xet-1.1.3-cp37-abi3-macosx_11_0_arm64.whl (2.2 MB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Using cached datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
      "Using cached peft-0.15.2-py3-none-any.whl (411 kB)\n",
      "Using cached mlflow-2.22.0-py3-none-any.whl (29.0 MB)\n",
      "Using cached mlflow_skinny-2.22.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached alembic-1.16.1-py3-none-any.whl (242 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Using cached cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached databricks_sdk-0.55.0-py3-none-any.whl (722 kB)\n",
      "Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Using cached fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "Using cached flask-3.1.1-py3-none-any.whl (103 kB)\n",
      "Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached google_auth-2.40.2-py2.py3-none-any.whl (216 kB)\n",
      "Using cached graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Using cached graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
      "Using cached graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "Using cached importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Using cached matplotlib-3.10.3-cp313-cp313-macosx_11_0_arm64.whl (8.1 MB)\n",
      "Using cached opentelemetry_api-1.34.0-py3-none-any.whl (65 kB)\n",
      "Using cached opentelemetry_sdk-1.34.0-py3-none-any.whl (118 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.55b0-py3-none-any.whl (196 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached protobuf-6.31.1-cp39-abi3-macosx_10_9_universal2.whl (425 kB)\n",
      "Using cached pyarrow-19.0.1-cp313-cp313-macosx_12_0_arm64.whl (30.7 MB)\n",
      "Using cached pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp313-cp313-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl (171 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp313-cp313-macosx_10_13_universal2.whl (199 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached scipy-1.15.3-cp313-cp313-macosx_14_0_arm64.whl (22.4 MB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached sqlalchemy-2.0.41-cp313-cp313-macosx_11_0_arm64.whl (2.1 MB)\n",
      "Using cached sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "Using cached starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached typing_extensions-4.14.0-py3-none-any.whl (43 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Using cached uvicorn-0.34.3-py3-none-any.whl (62 kB)\n",
      "Using cached aiohttp-3.12.8-cp313-cp313-macosx_11_0_arm64.whl (463 kB)\n",
      "Using cached multidict-6.4.4-cp313-cp313-macosx_11_0_arm64.whl (37 kB)\n",
      "Using cached yarl-1.20.0-cp313-cp313-macosx_11_0_arm64.whl (94 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Using cached contourpy-1.3.2-cp313-cp313-macosx_11_0_arm64.whl (255 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.58.1-cp313-cp313-macosx_10_13_universal2.whl (2.7 MB)\n",
      "Using cached frozenlist-1.6.2-cp313-cp313-macosx_11_0_arm64.whl (48 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached kiwisolver-1.4.8-cp313-cp313-macosx_11_0_arm64.whl (65 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached pillow-11.2.1-cp313-cp313-macosx_11_0_arm64.whl (3.0 MB)\n",
      "Using cached propcache-0.3.1-cp313-cp313-macosx_11_0_arm64.whl (44 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Using cached regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached zipp-3.22.0-py3-none-any.whl (9.8 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached xxhash-3.5.0-cp313-cp313-macosx_11_0_arm64.whl (30 kB)\n",
      "Installing collected packages: mpmath, zipp, xxhash, urllib3, typing-extensions, tqdm, threadpoolctl, sympy, sqlparse, sniffio, smmap, setuptools, scipy, safetensors, regex, pyyaml, pyparsing, pyasn1, pyarrow, protobuf, propcache, pillow, packaging, networkx, multidict, markupsafe, markdown, kiwisolver, joblib, itsdangerous, idna, hf-xet, h11, graphql-core, fsspec, frozenlist, fonttools, filelock, dill, cycler, contourpy, cloudpickle, click, charset-normalizer, certifi, cachetools, blinker, attrs, annotated-types, aiohappyeyeballs, yarl, werkzeug, uvicorn, typing-inspection, sqlalchemy, scikit-learn, rsa, requests, pydantic-core, pyasn1-modules, multiprocess, matplotlib, Mako, jinja2, importlib_metadata, gunicorn, graphql-relay, gitdb, anyio, aiosignal, torch, starlette, pydantic, opentelemetry-api, huggingface-hub, graphene, google-auth, gitpython, Flask, docker, alembic, aiohttp, tokenizers, opentelemetry-semantic-conventions, fastapi, databricks-sdk, accelerate, transformers, opentelemetry-sdk, datasets, peft, mlflow-skinny, mlflow\n",
      "\u001b[2K  Attempting uninstall: packaging0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/93\u001b[0m [propcache]]\n",
      "\u001b[2K    Found existing installation: packaging 25.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/93\u001b[0m [propcache]\n",
      "\u001b[2K    Uninstalling packaging-25.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/93\u001b[0m [propcache]\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/93\u001b[0m [propcache]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93/93\u001b[0m [mlflow] [mlflow]skinny]ets]ers]k]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Flask-3.1.1 Mako-1.3.10 accelerate-1.7.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.8 aiosignal-1.3.2 alembic-1.16.1 annotated-types-0.7.0 anyio-4.9.0 attrs-25.3.0 blinker-1.9.0 cachetools-5.5.2 certifi-2025.4.26 charset-normalizer-3.4.2 click-8.2.1 cloudpickle-3.1.1 contourpy-1.3.2 cycler-0.12.1 databricks-sdk-0.55.0 datasets-3.6.0 dill-0.3.8 docker-7.1.0 fastapi-0.115.12 filelock-3.18.0 fonttools-4.58.1 frozenlist-1.6.2 fsspec-2025.3.0 gitdb-4.0.12 gitpython-3.1.44 google-auth-2.40.2 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 h11-0.16.0 hf-xet-1.1.3 huggingface-hub-0.32.4 idna-3.10 importlib_metadata-8.7.0 itsdangerous-2.2.0 jinja2-3.1.6 joblib-1.5.1 kiwisolver-1.4.8 markdown-3.8 markupsafe-3.0.2 matplotlib-3.10.3 mlflow-2.22.0 mlflow-skinny-2.22.0 mpmath-1.3.0 multidict-6.4.4 multiprocess-0.70.16 networkx-3.5 opentelemetry-api-1.34.0 opentelemetry-sdk-1.34.0 opentelemetry-semantic-conventions-0.55b0 packaging-24.2 peft-0.15.2 pillow-11.2.1 propcache-0.3.1 protobuf-6.31.1 pyarrow-19.0.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.11.5 pydantic-core-2.33.2 pyparsing-3.2.3 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 rsa-4.9.1 safetensors-0.5.3 scikit-learn-1.5.2 scipy-1.15.3 setuptools-80.9.0 smmap-5.0.2 sniffio-1.3.1 sqlalchemy-2.0.41 sqlparse-0.5.3 starlette-0.46.2 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.21.1 torch-2.7.0 tqdm-4.67.1 transformers-4.52.4 typing-extensions-4.14.0 typing-inspection-0.4.1 urllib3-2.4.0 uvicorn-0.34.3 werkzeug-3.1.3 xxhash-3.5.0 yarl-1.20.0 zipp-3.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "add31525-5eeb-47e1-a9bf-9e178c8bd443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manishkumarsingh/Downloads/IISC-Root/DA 225o Deep Learning/Project/dost-com/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizer\n",
    "from datasets import Dataset as HFDataset\n",
    "\n",
    "KAGGLE_DATA_PATH = \"Base_data/training.csv\"\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "MAX_LENGTH = 128\n",
    "VAL_SIZE = 0.15\n",
    "TEST_SIZE = 0.1\n",
    "SAMPLE_SIZE = 3000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "917aaa9d-2fe4-444d-b3a6-226d2e81aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(KAGGLE_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4fb855b-4546-4120-add9-75700ef2a177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    4666\n",
       "1    5362\n",
       "2    1304\n",
       "3    2159\n",
       "4    1937\n",
       "5     572\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"label\"])[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd04e34e-f87c-4a55-954b-9c6b874025be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ive been taking or milligrams or times recommended amount and ive fallen asleep a lot faster but i also feel like so funny'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"label\"]==5][\"text\"][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f8898a5-f0ab-473e-bcd7-330040546fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                            i didnt feel humiliated      0\n",
       "1  i can go from feeling so hopeless to so damned...      0\n",
       "2   im grabbing a minute to post i feel greedy wrong      3\n",
       "3  i am ever feeling nostalgic about the fireplac...      2\n",
       "4                               i am feeling grouchy      3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48261bb3-ccf7-429c-8698-e89de5c2bb6e",
   "metadata": {},
   "source": [
    "## a classification label, with possible values including sadness (0), joy (1), love (2), anger (3), fear (4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccd92e59-d541-46b7-b3b7-50f2813e011c",
   "metadata": {},
   "outputs": [],
   "source": [
    " # set to an int (e.g., 4000) to subsample\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    df = pd.read_csv(KAGGLE_DATA_PATH)\n",
    "\n",
    "    if SAMPLE_SIZE:\n",
    "        df = df.sample(n=SAMPLE_SIZE, random_state=42)\n",
    "\n",
    "    labels = sorted(df[\"label\"].unique())\n",
    "    label2id = {l: i for i, l in enumerate(labels)}\n",
    "    id2label = {i: l for l, i in label2id.items()}\n",
    "    df[\"label\"] = df[\"label\"].map(label2id)\n",
    "\n",
    "    train_val, test = train_test_split(\n",
    "        df,\n",
    "        test_size=TEST_SIZE,\n",
    "        stratify=df[\"label\"],\n",
    "        random_state=42,\n",
    "    )\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_val,\n",
    "        test_size=VAL_SIZE,\n",
    "        stratify=train_val[\"label\"],\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    def tokenize(batch):\n",
    "        return tokenizer(\n",
    "            batch[\"text\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=MAX_LENGTH,\n",
    "        )\n",
    "\n",
    "    train_ds = HFDataset.from_pandas(train_df[[\"text\", \"label\"]]).map(tokenize, batched=True)\n",
    "    val_ds = HFDataset.from_pandas(val_df[[\"text\", \"label\"]]).map(tokenize, batched=True)\n",
    "    test_ds = HFDataset.from_pandas(test[[\"text\", \"label\"]]).map(tokenize, batched=True)\n",
    "\n",
    "    for ds in (train_ds, val_ds, test_ds):\n",
    "        ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "    return train_ds, val_ds, test_ds, len(labels), label2id, id2label\n",
    "\n",
    "\n",
    "\n",
    "# train_ds, val_ds, test_ds, num_labels, label2id, id2label = load_data()\n",
    "# print(f\"Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bf16652-99ad-46b6-8d1f-e02076702136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2295/2295 [00:00<00:00, 7354.12 examples/s]\n",
      "Map: 100%|██████████| 405/405 [00:00<00:00, 7819.72 examples/s]\n",
      "Map: 100%|██████████| 300/300 [00:00<00:00, 7797.07 examples/s]\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    train_tokenized,\n",
    "    val_tokenized,\n",
    "    unseen_test_tokenized,\n",
    "    num_labels,\n",
    "    label2id,\n",
    "    id2label\n",
    ") = load_data()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bcdea9-cd14-41fe-96eb-097d0885d808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 2295/2295 [00:00<00:00, 914056.37 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 405/405 [00:00<00:00, 265919.40 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 300/300 [00:00<00:00, 209785.13 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "import json, os\n",
    "\n",
    "base_dir = \"data\"                   \n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "train_tokenized.save_to_disk(f\"{base_dir}/train\")\n",
    "val_tokenized.save_to_disk(f\"{base_dir}/val\")\n",
    "unseen_test_tokenized.save_to_disk(f\"{base_dir}/test\")\n",
    "\n",
    "clean_id2label = {int(k): v for k, v in id2label.items()}   \n",
    "clean_label2id = {str(k): int(v) for k, v in label2id.items()} \n",
    "\n",
    "import json, numpy as np, os\n",
    "\n",
    "def to_py(obj):\n",
    "    \"\"\"Recursively cast numpy scalars to plain Python.\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {to_py(k): to_py(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [to_py(x) for x in obj]\n",
    "    if isinstance(obj, np.generic):         \n",
    "        return obj.item()                   \n",
    "    return obj                               \n",
    "\n",
    "payload = {\n",
    "    \"label2id\": label2id,\n",
    "    \"id2label\": id2label,\n",
    "    \"num_labels\": num_labels\n",
    "}\n",
    "payload = to_py(payload)                     \n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "with open(f\"{base_dir}/label_maps.json\", \"w\") as fp:\n",
    "    json.dump(payload, fp, indent=2)\n",
    "train_ds   = load_from_disk(f\"{base_dir}/train\")\n",
    "val_ds     = load_from_disk(f\"{base_dir}/val\")\n",
    "test_ds    = load_from_disk(f\"{base_dir}/test\")\n",
    "\n",
    "with open(f\"{base_dir}/label_maps.json\") as fp:\n",
    "    maps = json.load(fp)\n",
    "label2id  = maps[\"label2id\"]\n",
    "id2label  = maps[\"id2label\"]\n",
    "num_labels = maps[\"num_labels\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
